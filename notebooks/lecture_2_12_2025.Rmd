---
title: "Lecture 2/12/2025"
output: html_document
date: "2025-02-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ISLR2)
library(MASS) # for LDA and QDA regressions
```

# Bayesian Classifiers

## LDA in 1 Variable

### Generate mixture model data

```{r}
set.seed(100) # set seed for reproducibility
# defines and the standard devs of the two Gaussians
mu=c(-1, 2)
sigma=c(1., 1.)
# prior probabilities
prior=c(0.3, 0.7)

# number of total samples we draw from the mixture model
n = 10^4

# first sample the class varaible n times
class=sample(1:2,n,replace = TRUE, prob = prior)
# convert to categorical variable
class=as.factor(class)
# sample the x values (what we measure in practice)
# preallocates the array
x=numeric(n)
for(j in 1:n){
  # sample Gaussian 1 or Gaussian 2 as appropriate
  x[j] =rnorm(1,mean = mu[class[j]], sd = sigma[class[j]])
}
# store as a tibble
mixture.df <- tibble("class"=class, "x"=x)
mixture.df
```

```{r}
hist.split = ggplot(mixture.df, aes(x=x, fill=class)) + 
  geom_histogram(alpha=0.5, bins=50, position ="identity") + 
  ggtitle("Data Split by Class") + labs(fill="Class")
#show the plot 
print(hist.split)
```

Note the overlap region; this is where the errors will be.

### the LDA Model

```{r}
lda.fit = lda(class~x, data = mixture.df) # fits the LDA classifier, given the data, and the model class ~ x
lda.fit
```

### Check Performance

```{r}
# generates the predictions on the trained classifier
pred.train = predict(lda.fit,newdata = mixture.df)
# construct a data frame for plotting
lda.df=tibble(x=mixture.df$x, true = mixture.df$class, 
              pred=pred.train$class, 
              p=pred.train$posterior[,1], # predicted and probability
              correct = (mixture.df$class==pred.train$class)) # correct or not

```

```{r}
lda.df
```

Accuracy

```{r}
mean(lda.df$correct)
```

Visualize

```{r}
plot.lda = ggplot(data = lda.df, aes(shape=pred, color=correct)) + 
  geom_point(aes(x=x,y=p)) + 
  ggtitle("LDA Classifier")
print(plot.lda)
```

Note: The errors all occur in the region where the Gaussians overlap.

### Compare with Logistic

```{r}
logistic.fit=glm(class~x,data=mixture.df, family = binomial)
logistic.prob=as_tibble(predict(logistic.fit, type = "response"))
logistic.pred=rep(1, nrow(mixture.df))
logistic.pred[logistic.prob>0.5] <-2
logistic.df=tibble(x=mixture.df$x, true = mixture.df$class,
                   pred=as.factor(logistic.pred), 
                   p=pred.train$posterior[,1],
                   correct = (mixture.df$class==logistic.pred))
```

```{r}
mean(logistic.df$correct)
```

Not so different than LDA.

```{r}
plot.logistic= ggplot(data = logistic.df, aes(shape=pred, color=correct)) +
  geom_point(aes(x=x,y=p)) + 
  ggtitle("Logistic Classifier")
print(plot.logistic)

```
